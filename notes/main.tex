\documentclass{article}
\input{include.tex}

% Graphics path
\graphicspath{{./figs}}

% invert color. change \mdfdefinestyle{problemstyle} command if submitting document
\pagecolor{black}
\color{white}

\title{Math 556 - Applied Functional Analysis}
\author{Autumn 2024}

\begin{document}  
\frenchspacing
\maketitle 
\section*{28 August 2024}
\subsection*{Introduction}
Why do we look at spaces of functions? First, we can consider the geometric view. That is, we look at functions as elements of a function space in a manner analogous to the way we view vectors in a vector space. Just like a vector space, function spaces are \textit{linear spaces}. Furthermore, we can quantify the distances between functions using a \textit{metric}. For instance, consider the metric 
    \[
        \rho(f, g) = \sup_{x} |f(x) - g(x)|.
    \]
There are several natural choices for distances. We could consider something of the form 
    \[
        \rho(f, g) = \int |f(x) - g(x) | \, \t{d}x,
    \]
or perhaps
    \[
        \rho^p(f, g) = \left(\int |f(x) - g(x)|^p \, \t{d}x \right)^{1/p}.
    \]
These two metrics define different function spaces. 
\newpar

Another purpose of functional analysis is to ``generalize useful concepts.'' For instance, spectral methods can be used to solve systems of linear equations and ODEs. Let $A$ be a $n \times n$ symmetric amtrix with real entries. We can consider the system of equations $Ax = y$. If $A$ is invertible, the solution to the system is unique and $x = A^{-1} y$. There is a natural parallel to the existance and uniqueness theorem from the study of ODEs.
\newpar

But suppose we want an explicit form of $x$. To acheive this information, we need more information on $A^{-1}$, so we consider the eigenproblem for $A$. That is we find the vectors $u_i$, $i \in \{1, \hdots, n\}$ satisfying $Au_i = \lambda_i u_i$ for some scalarvalues $u_i$. Since $A$ is symmetric, the eigenvalues are real and the eigenvectors are orthogonal to each other. Furthermore, we can choose $u_i$ so that $\langle u_i, u_j \rangle = \delta_{i, j}$, where the inner product $\langle x, y\rangle = \sum_i x_i y_i$ in this case. These vectors form an orthonormal basis of $\R^n$, and we can expand $x$ and $y$ by
    \[
        x = \sum_i a_i u_i, \quad y = \sum_i b_i u_i, 
    \]
so, we write
    \[
        Ax = \sum_i a_i \lambda_i u_i 
    \]
and by combining a few equations, we can write down
    \[
        \sum_i (a_i \lambda_i - b_i) u_i = 0.
    \]
Since $\{u_1, \hdots, u_n\}$ form an orthonormal basis, we can deduce that $a_i = b_i / \lambda_i$, and thus 
    \[
        x = \sum_i \frac{b_i u_i}{\lambda_i}.
    \]
We can note that $b_i = \langle u_i, y \rangle$, so we get
    \[
        x = \sum_i \frac{1}{\lambda_i} \langle u_i, y \rangle u_i,
    \]
so we arrive at our spectral representation of $x$. Furthermore, we can find the $n$-th coordinate by observing
    \begin{align*}
        x_n &= \sum_i \frac{1}{\lambda_i} \langle u_i, y \rangle (u_i)_n \\
        &= \sum_m \left(\sum_i \frac{1}{\lambda_i} (u_i)_m (u_i)_n\right)y_m.
    \end{align*}
From this, since $x_n = \sum_m A^{-1}_{n,m} y_m$, from the solution, we can deduce that 
    \[
        A_{n, m}^{-1} = \sum_{i} \frac{1}{\lambda_i}(u_i)_n (u_i)_m,
    \]
which is called the spectral decomposition of $A^{-1}$. We will generalize this notion to functional spaces in this course. 
\newpar

Now, let us consider the ODE $u'' + k^2u = f$ with the boundary condition $u(0) = u(\pi) = 0$ for some constant $k \in \R$. This is equivalent to solving the eigenproblem $-\phi'' = k \phi$ with $\phi(0) = \phi(\pi) = 0$. The general solution of the eigenproblem is given by $\phi(x) = A \cos(\sqrt{\lambda}x) + B \sin(\sqrt{\lambda} x)$, with $A$ and $B$ constant. We can use the boundary condition , adn we can also normalize by the condition 
    \[
        \int_0^\pi |\phi(x)| \, \t{d}x = 1.
    \]
Doing these computations can be taken as an exercise. In general, we will show in this course that 
    \[
        u(x) = \int G(x, y) f(y) \, \t{d}y,
    \]
where 
    \[
        G(x, y) = \sum_n \frac{\phi_n(x) \phi_n(y)}{k^2 - \lambda_n^2}.
    \]
$G(x, y)$ is called \textit{Green's function}. In fact, from this differential equation, we can derive
    \[
        \left( \frac{\partial^2}{\partial x^2} + k^2\right)G(x - y) = \delta(x - y),
    \]
where $\delta$ is the \textit{Dirac Distribution}.
\end{document}